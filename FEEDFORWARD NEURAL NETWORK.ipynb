{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HhhaFIy9W5w"
      },
      "source": [
        "## Feed Forward Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97IgdI5L9VX8",
        "outputId": "0d6b887a-fb2c-4c1c-b187-a0580476e722"
      },
      "outputs": [],
      "source": [
        "# Data Load\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    data_dir = '/content/drive/Shareddrives/EEE405 Group Project/MagnetChallenge/data'\n",
        "else:\n",
        "    data_dir = 'C:/Users/moyin/Desktop/N87'\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def load_material_data(material, data_dir=data_dir, first_row=0, last_row=None):\n",
        "    \"\"\"\n",
        "    Load the material data from the data directory.\n",
        "    :return: dict of pandas dataframes\n",
        "    \"\"\"\n",
        "    material_dir = os.path.join(data_dir, material + \"_cycle\")\n",
        "    if last_row is not None:\n",
        "        nrows = last_row - first_row + 1\n",
        "    else:\n",
        "        nrows = None\n",
        "\n",
        "    return {\n",
        "        \"Freq\": pd.read_csv(os.path.join(material_dir, \"Frequency[Hz].csv\"), nrows=nrows, header=None, skiprows=first_row),\n",
        "        \"Temp\": pd.read_csv(os.path.join(material_dir, \"Temperature[C].csv\"), nrows=nrows, header=None, skiprows=first_row),\n",
        "        \"B\": pd.read_csv(os.path.join(material_dir, \"B_waveform[T].csv\"), header=None, nrows=nrows, skiprows=first_row),\n",
        "        \"H\": pd.read_csv(os.path.join(material_dir, \"H_waveform[Am-1].csv\"), header=None, nrows=nrows, skiprows=first_row),\n",
        "        \"Loss\": pd.read_csv(os.path.join(material_dir, \"Volumetric_losses[Wm-3].csv\"), header=None, nrows=nrows, names=[\"Loss\"], skiprows=first_row),\n",
        "    }\n",
        "\n",
        "# Load data for different waveforms\n",
        "# sine(0,337) triangle(338,3649) trap(3650,10151)\n",
        "dfs = load_material_data(\"N87\", first_row=0, last_row=10151)\n",
        "dfs[\"Bpk\"] = dfs[\"B\"].max(axis=1)\n",
        "def EstimateTriangleDuty(B):\n",
        "    \"\"\"Estimate the duty cycle of the triangle wave based on the index of the peak value\"\"\"\n",
        "    Bpk = B.idxmax()\n",
        "    return 100 * Bpk / len(B)\n",
        "dfs[\"Duty\"] = dfs[\"B\"].apply(EstimateTriangleDuty, axis=1)\n",
        "\n",
        "X = np.column_stack(\n",
        "    (\n",
        "        np.log10(dfs[\"Freq\"].to_numpy()),\n",
        "        np.log10(dfs[\"Bpk\"].to_numpy()),\n",
        "        dfs[\"Duty\"]\n",
        "    )\n",
        ")\n",
        "y = np.log10(dfs[\"Loss\"].to_numpy())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "p9XHbURO5kY2"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# X and y input features and target labels\n",
        "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y, dtype=torch.float32).view(-1, 1) # reshape for the output layer\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
        "\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Create a dataset and data loader\n",
        "dataset = TensorDataset(X_tensor, y_tensor)\n",
        "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/100], Loss: 0.2489, Avg RPE: 8.81%, Max RPE: 37.48%\n",
            "Epoch [2/100], Loss: 0.0232, Avg RPE: 1.85%, Max RPE: 13.31%\n",
            "Epoch [3/100], Loss: 0.0298, Avg RPE: 2.19%, Max RPE: 14.86%\n",
            "Epoch [4/100], Loss: 0.0244, Avg RPE: 1.54%, Max RPE: 12.35%\n",
            "Epoch [5/100], Loss: 0.0187, Avg RPE: 1.78%, Max RPE: 10.79%\n",
            "Epoch [6/100], Loss: 0.0081, Avg RPE: 1.92%, Max RPE: 15.01%\n",
            "Epoch [7/100], Loss: 0.0249, Avg RPE: 1.88%, Max RPE: 9.88%\n",
            "Epoch [8/100], Loss: 0.0050, Avg RPE: 1.54%, Max RPE: 10.18%\n",
            "Epoch [9/100], Loss: 0.0109, Avg RPE: 1.51%, Max RPE: 10.07%\n",
            "Epoch [10/100], Loss: 0.0032, Avg RPE: 1.58%, Max RPE: 11.02%\n",
            "Epoch [11/100], Loss: 0.0050, Avg RPE: 2.97%, Max RPE: 12.95%\n",
            "Epoch [12/100], Loss: 0.0143, Avg RPE: 2.17%, Max RPE: 10.18%\n",
            "Epoch [13/100], Loss: 0.0066, Avg RPE: 1.70%, Max RPE: 10.11%\n",
            "Epoch [14/100], Loss: 0.0211, Avg RPE: 2.07%, Max RPE: 10.63%\n",
            "Epoch [15/100], Loss: 0.0078, Avg RPE: 1.88%, Max RPE: 9.66%\n",
            "Epoch [16/100], Loss: 0.0058, Avg RPE: 1.55%, Max RPE: 9.21%\n",
            "Epoch [17/100], Loss: 0.0168, Avg RPE: 1.47%, Max RPE: 9.57%\n",
            "Epoch [18/100], Loss: 0.0195, Avg RPE: 1.57%, Max RPE: 10.93%\n",
            "Epoch [19/100], Loss: 0.0102, Avg RPE: 1.55%, Max RPE: 11.06%\n",
            "Epoch [20/100], Loss: 0.0086, Avg RPE: 1.90%, Max RPE: 10.05%\n",
            "Epoch [21/100], Loss: 0.0078, Avg RPE: 1.92%, Max RPE: 13.23%\n",
            "Epoch [22/100], Loss: 0.0060, Avg RPE: 1.64%, Max RPE: 9.00%\n",
            "Epoch [23/100], Loss: 0.0116, Avg RPE: 1.39%, Max RPE: 9.20%\n",
            "Epoch [24/100], Loss: 0.0051, Avg RPE: 1.42%, Max RPE: 8.86%\n",
            "Epoch [25/100], Loss: 0.0136, Avg RPE: 1.54%, Max RPE: 10.59%\n",
            "Epoch [26/100], Loss: 0.0045, Avg RPE: 1.54%, Max RPE: 9.03%\n",
            "Epoch [27/100], Loss: 0.0046, Avg RPE: 1.71%, Max RPE: 10.15%\n",
            "Epoch [28/100], Loss: 0.0102, Avg RPE: 2.48%, Max RPE: 10.73%\n",
            "Epoch [29/100], Loss: 0.0268, Avg RPE: 1.69%, Max RPE: 9.63%\n",
            "Epoch [30/100], Loss: 0.0078, Avg RPE: 2.06%, Max RPE: 13.01%\n",
            "Epoch [31/100], Loss: 0.0083, Avg RPE: 1.53%, Max RPE: 8.55%\n",
            "Epoch [32/100], Loss: 0.0133, Avg RPE: 1.35%, Max RPE: 9.93%\n",
            "Epoch [33/100], Loss: 0.0160, Avg RPE: 1.70%, Max RPE: 12.65%\n",
            "Epoch [34/100], Loss: 0.0204, Avg RPE: 1.77%, Max RPE: 9.83%\n",
            "Epoch [35/100], Loss: 0.0195, Avg RPE: 1.38%, Max RPE: 9.64%\n",
            "Epoch [36/100], Loss: 0.0209, Avg RPE: 1.83%, Max RPE: 8.27%\n",
            "Epoch [37/100], Loss: 0.0069, Avg RPE: 1.51%, Max RPE: 9.04%\n",
            "Epoch [38/100], Loss: 0.0190, Avg RPE: 1.56%, Max RPE: 11.27%\n",
            "Epoch [39/100], Loss: 0.0078, Avg RPE: 1.49%, Max RPE: 10.90%\n",
            "Epoch [40/100], Loss: 0.0103, Avg RPE: 1.57%, Max RPE: 9.64%\n",
            "Epoch [41/100], Loss: 0.0123, Avg RPE: 1.43%, Max RPE: 10.04%\n",
            "Epoch [42/100], Loss: 0.0075, Avg RPE: 1.44%, Max RPE: 8.17%\n",
            "Epoch [43/100], Loss: 0.0048, Avg RPE: 2.23%, Max RPE: 10.54%\n",
            "Epoch [44/100], Loss: 0.0051, Avg RPE: 1.45%, Max RPE: 10.21%\n",
            "Epoch [45/100], Loss: 0.0223, Avg RPE: 1.76%, Max RPE: 11.14%\n",
            "Epoch [46/100], Loss: 0.0095, Avg RPE: 1.84%, Max RPE: 9.35%\n",
            "Epoch [47/100], Loss: 0.0073, Avg RPE: 1.40%, Max RPE: 9.32%\n",
            "Epoch [48/100], Loss: 0.0095, Avg RPE: 1.74%, Max RPE: 10.52%\n",
            "Epoch [49/100], Loss: 0.0120, Avg RPE: 1.44%, Max RPE: 10.33%\n",
            "Epoch [50/100], Loss: 0.0115, Avg RPE: 4.09%, Max RPE: 17.43%\n",
            "Epoch [51/100], Loss: 0.0065, Avg RPE: 1.46%, Max RPE: 8.55%\n",
            "Epoch [52/100], Loss: 0.0270, Avg RPE: 3.09%, Max RPE: 10.92%\n",
            "Epoch [53/100], Loss: 0.0132, Avg RPE: 1.52%, Max RPE: 9.90%\n",
            "Epoch [54/100], Loss: 0.0091, Avg RPE: 1.71%, Max RPE: 9.33%\n",
            "Epoch [55/100], Loss: 0.0088, Avg RPE: 1.47%, Max RPE: 9.27%\n",
            "Epoch [56/100], Loss: 0.0167, Avg RPE: 3.50%, Max RPE: 14.59%\n",
            "Epoch [57/100], Loss: 0.0263, Avg RPE: 1.42%, Max RPE: 9.15%\n",
            "Epoch [58/100], Loss: 0.0149, Avg RPE: 2.74%, Max RPE: 12.97%\n",
            "Epoch [59/100], Loss: 0.0124, Avg RPE: 1.35%, Max RPE: 8.49%\n",
            "Epoch [60/100], Loss: 0.0079, Avg RPE: 2.08%, Max RPE: 9.43%\n",
            "Epoch [61/100], Loss: 0.0072, Avg RPE: 1.66%, Max RPE: 11.09%\n",
            "Epoch [62/100], Loss: 0.0074, Avg RPE: 1.38%, Max RPE: 8.48%\n",
            "Epoch [63/100], Loss: 0.0067, Avg RPE: 2.01%, Max RPE: 10.43%\n",
            "Epoch [64/100], Loss: 0.0153, Avg RPE: 1.61%, Max RPE: 10.92%\n",
            "Epoch [65/100], Loss: 0.0162, Avg RPE: 1.33%, Max RPE: 8.87%\n",
            "Epoch [66/100], Loss: 0.0120, Avg RPE: 1.34%, Max RPE: 9.26%\n",
            "Epoch [67/100], Loss: 0.0177, Avg RPE: 1.83%, Max RPE: 11.43%\n",
            "Epoch [68/100], Loss: 0.0078, Avg RPE: 2.05%, Max RPE: 10.26%\n",
            "Epoch [69/100], Loss: 0.0723, Avg RPE: 1.46%, Max RPE: 10.11%\n",
            "Epoch [70/100], Loss: 0.0072, Avg RPE: 2.36%, Max RPE: 11.42%\n",
            "Epoch [71/100], Loss: 0.0066, Avg RPE: 1.69%, Max RPE: 11.61%\n",
            "Epoch [72/100], Loss: 0.0047, Avg RPE: 1.48%, Max RPE: 9.01%\n",
            "Epoch [73/100], Loss: 0.0175, Avg RPE: 1.58%, Max RPE: 9.44%\n",
            "Epoch [74/100], Loss: 0.0057, Avg RPE: 1.63%, Max RPE: 11.79%\n",
            "Epoch [75/100], Loss: 0.0257, Avg RPE: 1.43%, Max RPE: 8.08%\n",
            "Epoch [76/100], Loss: 0.0076, Avg RPE: 1.39%, Max RPE: 8.26%\n",
            "Epoch [77/100], Loss: 0.0040, Avg RPE: 1.63%, Max RPE: 9.58%\n",
            "Epoch [78/100], Loss: 0.0082, Avg RPE: 1.52%, Max RPE: 10.17%\n",
            "Epoch [79/100], Loss: 0.0103, Avg RPE: 1.48%, Max RPE: 9.19%\n",
            "Epoch [80/100], Loss: 0.0086, Avg RPE: 1.38%, Max RPE: 8.48%\n",
            "Epoch [81/100], Loss: 0.0227, Avg RPE: 1.39%, Max RPE: 8.64%\n",
            "Epoch [82/100], Loss: 0.0039, Avg RPE: 1.46%, Max RPE: 9.81%\n",
            "Epoch [83/100], Loss: 0.0074, Avg RPE: 1.59%, Max RPE: 9.69%\n",
            "Epoch [84/100], Loss: 0.0136, Avg RPE: 1.44%, Max RPE: 9.32%\n",
            "Epoch [85/100], Loss: 0.0072, Avg RPE: 1.37%, Max RPE: 9.43%\n",
            "Epoch [86/100], Loss: 0.0087, Avg RPE: 1.41%, Max RPE: 9.48%\n",
            "Epoch [87/100], Loss: 0.0133, Avg RPE: 1.59%, Max RPE: 10.53%\n",
            "Epoch [88/100], Loss: 0.0065, Avg RPE: 1.42%, Max RPE: 7.56%\n",
            "Epoch [89/100], Loss: 0.0079, Avg RPE: 1.35%, Max RPE: 8.02%\n",
            "Epoch [90/100], Loss: 0.0028, Avg RPE: 1.36%, Max RPE: 10.45%\n",
            "Epoch [91/100], Loss: 0.0091, Avg RPE: 1.37%, Max RPE: 8.43%\n",
            "Epoch [92/100], Loss: 0.0082, Avg RPE: 1.37%, Max RPE: 7.84%\n",
            "Epoch [93/100], Loss: 0.0073, Avg RPE: 1.56%, Max RPE: 8.22%\n",
            "Epoch [94/100], Loss: 0.0057, Avg RPE: 1.34%, Max RPE: 8.57%\n",
            "Epoch [95/100], Loss: 0.0111, Avg RPE: 1.44%, Max RPE: 9.78%\n",
            "Epoch [96/100], Loss: 0.0103, Avg RPE: 1.45%, Max RPE: 8.38%\n",
            "Epoch [97/100], Loss: 0.0055, Avg RPE: 1.42%, Max RPE: 11.33%\n",
            "Epoch [98/100], Loss: 0.0093, Avg RPE: 1.53%, Max RPE: 7.56%\n",
            "Epoch [99/100], Loss: 0.0205, Avg RPE: 1.71%, Max RPE: 10.54%\n",
            "Epoch [100/100], Loss: 0.0156, Avg RPE: 1.37%, Max RPE: 9.19%\n"
          ]
        }
      ],
      "source": [
        "# Define the neural network architecture\n",
        "class MagneticLossPredictor(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(MagneticLossPredictor, self).__init__()\n",
        "        # Define the first hidden layer with 5 neurons\n",
        "        self.fc1 = nn.Linear(input_size, 4)\n",
        "        # Define the second hidden layer with 8 neuron\n",
        "        self.fc2 = nn.Linear(4, 36)\n",
        "        # Define the third hidden layer with 5 neurons\n",
        "        self.fc3 = nn.Linear(36, 21)\n",
        "        # Define the output layer\n",
        "        self.fc4 = nn.Linear(21, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass the input through the first hidden layer and apply the ReLU activation function\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        # Pass the output of the first layer to the second hidden layer and apply ReLU\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        # Pass the output of the second layer to the third hidden layer and apply ReLU\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        # Pass the output of the third layer to the output layer\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "# Create the model\n",
        "model = MagneticLossPredictor(input_size=3, output_size=1)\n",
        "\n",
        "# Define the loss function and the optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.004)\n",
        "\n",
        "# Function to calculate the relative errors\n",
        "def RelativeError(y_test, y_pred):\n",
        "    AvgRPE = 100 * (torch.abs(y_test - y_pred) / y_test).mean().item()\n",
        "    MaxRPE = 100 * (torch.abs(y_test - y_pred) / y_test).max().item()\n",
        "    return AvgRPE, MaxRPE\n",
        "\n",
        "\n",
        "num_epochs = 100\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    # Training phase\n",
        "    model.train()\n",
        "    for inputs, targets in train_loader:\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Evaluation phase\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Concatenate all batches\n",
        "        predictions, actuals = torch.tensor([]), torch.tensor([])\n",
        "        for inputs, targets in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            predictions = torch.cat((predictions, outputs), 0)\n",
        "            actuals = torch.cat((actuals, targets), 0)\n",
        "\n",
        "        # Calculate relative errors\n",
        "        avg_rpe, max_rpe = RelativeError(actuals, predictions)\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Avg RPE: {avg_rpe:.2f}%, Max RPE: {max_rpe:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'trained_modelupdated.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MagneticLossPredictor(\n",
              "  (fc1): Linear(in_features=3, out_features=4, bias=True)\n",
              "  (fc2): Linear(in_features=4, out_features=36, bias=True)\n",
              "  (fc3): Linear(in_features=36, out_features=21, bias=True)\n",
              "  (fc4): Linear(in_features=21, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loaded_model = MagneticLossPredictor(input_size=3, output_size=1)\n",
        "loaded_model.load_state_dict(torch.load('trained_modelupdated.pth'))\n",
        "loaded_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Avg RPE for sine_dfs: 1.51%, Max RPE for sine_dfs: 4.40%\n"
          ]
        }
      ],
      "source": [
        "# Function to calculate the relative errors\n",
        "def RelativeError(y_test, y_pred):\n",
        "    y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
        "    y_pred_tensor = torch.tensor(y_pred, dtype=torch.float32)\n",
        "    \n",
        "    AvgRPE = 100 * (torch.abs(y_test_tensor - y_pred_tensor) / y_test_tensor).mean().item()\n",
        "    MaxRPE = 100 * (torch.abs(y_test_tensor - y_pred_tensor) / y_test_tensor).max().item()\n",
        "    return AvgRPE, MaxRPE\n",
        "\n",
        "\n",
        "loaded_model = MagneticLossPredictor(input_size=3, output_size=1)\n",
        "loaded_model.load_state_dict(torch.load('trained_modelupdated.pth'))\n",
        "loaded_model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Load the data for sine_dfs\n",
        "sine_dfs = load_material_data(\"N87\", first_row=0, last_row=337)\n",
        "sine_dfs[\"Bpk\"] = sine_dfs[\"B\"].max(axis=1)\n",
        "sine_dfs[\"Duty\"] = sine_dfs[\"B\"].apply(EstimateTriangleDuty, axis=1)\n",
        "\n",
        "# Prepare the input features (X) for prediction\n",
        "X_sine = np.column_stack(\n",
        "    (\n",
        "        np.log10(sine_dfs[\"Freq\"].to_numpy()),\n",
        "        np.log10(sine_dfs[\"Bpk\"].to_numpy()),\n",
        "        sine_dfs[\"Duty\"]\n",
        "    )\n",
        ")\n",
        "X_sine_tensor = torch.tensor(X_sine, dtype=torch.float32)\n",
        "\n",
        "# Make predictions\n",
        "with torch.no_grad():\n",
        "    predictions_sine = loaded_model(X_sine_tensor)\n",
        "\n",
        "\n",
        "y_test_sine = np.log10(sine_dfs[\"Loss\"].to_numpy())\n",
        "\n",
        "# Calculate relative errors\n",
        "avg_rpe_sine, max_rpe_sine = RelativeError(y_test_sine, predictions_sine.numpy())\n",
        "\n",
        "# Print or use the relative errors as needed\n",
        "print(f'Avg RPE for sine_dfs: {avg_rpe_sine:.2f}%, Max RPE for sine_dfs: {max_rpe_sine:.2f}%')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Avg RPE for trap_dfs: 1.36%, Max RPE for trap_dfs: 8.19%\n"
          ]
        }
      ],
      "source": [
        "trap_dfs = load_material_data(\"N87\", first_row=3650, last_row=10151)\n",
        "trap_dfs[\"Bpk\"] = trap_dfs[\"B\"].max(axis=1)\n",
        "trap_dfs[\"Duty\"] = trap_dfs[\"B\"].apply(EstimateTriangleDuty, axis=1)\n",
        "\n",
        "# Prepare the input features (X) for prediction\n",
        "X_trap = np.column_stack(\n",
        "    (\n",
        "        np.log10(trap_dfs[\"Freq\"].to_numpy()),\n",
        "        np.log10(trap_dfs[\"Bpk\"].to_numpy()),\n",
        "        trap_dfs[\"Duty\"]\n",
        "    )\n",
        ")\n",
        "X_trap_tensor = torch.tensor(X_trap, dtype=torch.float32)\n",
        "\n",
        "# Make predictions\n",
        "with torch.no_grad():\n",
        "    predictions_trap = loaded_model(X_trap_tensor)\n",
        "\n",
        "# The 'predictions_trap' tensor now contains the model's predictions for the trap_dfs data\n",
        "\n",
        "# Assuming y_test is the ground truth for trap_dfs\n",
        "y_test_trap = np.log10(trap_dfs[\"Loss\"].to_numpy())\n",
        "\n",
        "# Calculate relative errors\n",
        "avg_rpe_trap, max_rpe_trap = RelativeError(y_test_trap, predictions_trap.numpy())\n",
        "\n",
        "# Print or use the relative errors as needed\n",
        "print(f'Avg RPE for trap_dfs: {avg_rpe_trap:.2f}%, Max RPE for trap_dfs: {max_rpe_trap:.2f}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Avg RPE for triangle_dfs: 1.41%, Max RPE for triangle_dfs: 11.46%\n"
          ]
        }
      ],
      "source": [
        "triangle_dfs = load_material_data(\"N87\", first_row=338, last_row=3649)\n",
        "triangle_dfs[\"Bpk\"] = triangle_dfs[\"B\"].max(axis=1)\n",
        "triangle_dfs[\"Duty\"] = triangle_dfs[\"B\"].apply(EstimateTriangleDuty, axis=1)\n",
        "\n",
        "# Prepare the input features (X) for prediction\n",
        "X_triangle = np.column_stack(\n",
        "    (\n",
        "        np.log10(triangle_dfs[\"Freq\"].to_numpy()),\n",
        "        np.log10(triangle_dfs[\"Bpk\"].to_numpy()),\n",
        "        triangle_dfs[\"Duty\"]\n",
        "    )\n",
        ")\n",
        "X_triangle_tensor = torch.tensor(X_triangle, dtype=torch.float32)\n",
        "\n",
        "# Make predictions\n",
        "with torch.no_grad():\n",
        "    predictions_triangle = loaded_model(X_triangle_tensor)\n",
        "\n",
        "\n",
        "\n",
        "y_test_triangle = np.log10(triangle_dfs[\"Loss\"].to_numpy())\n",
        "\n",
        "# Calculate relative errors\n",
        "avg_rpe_triangle, max_rpe_triangle = RelativeError(y_test_triangle, predictions_triangle.numpy())\n",
        "\n",
        "# Print or use the relative errors as needed\n",
        "print(f'Avg RPE for triangle_dfs: {avg_rpe_triangle:.2f}%, Max RPE for triangle_dfs: {max_rpe_triangle:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "results_table = pd.DataFrame({\n",
        "    'Dataset': ['sine_dfs', 'triangle_dfs', 'trap_dfs'],\n",
        "    'AvgRPE': [f'{avg_rpe_sine:.2f}%', f'{avg_rpe_triangle:.2f}%', f'{avg_rpe_trap:.2f}%'],\n",
        "    'MaxRPE': [f'{max_rpe_sine:.2f}%', f'{max_rpe_triangle:.2f}%', f'{max_rpe_trap:.2f}%']\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results Table for N87 in percentage:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset</th>\n",
              "      <th>AvgRPE</th>\n",
              "      <th>MaxRPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sine_dfs</td>\n",
              "      <td>1.51%</td>\n",
              "      <td>4.40%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>triangle_dfs</td>\n",
              "      <td>1.41%</td>\n",
              "      <td>11.46%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>trap_dfs</td>\n",
              "      <td>1.36%</td>\n",
              "      <td>8.19%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Dataset AvgRPE  MaxRPE\n",
              "0      sine_dfs  1.51%   4.40%\n",
              "1  triangle_dfs  1.41%  11.46%\n",
              "2      trap_dfs  1.36%   8.19%"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Results Table for N87 in percentage:\")\n",
        "results_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "import openpyxl\n",
        "results_table.style.background_gradient(axis=None, low=0.75, high=1.0).to_excel(\"FNN.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Visualize the results\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(results_table['Dataset'], results_table['AvgRPE'].str.rstrip('%').astype('float'), label='AvgRPE')\n",
        "plt.bar(results_table['Dataset'], results_table['MaxRPE'].str.rstrip('%').astype('float'), label='MaxRPE', alpha=0.7)\n",
        "plt.title('Relative Errors for Different Datasets')\n",
        "plt.xlabel('Dataset')\n",
        "plt.ylabel('Relative Error (%)')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## OPTUNA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-11-29 10:50:07,757] A new study created in memory with name: no-name-ea9aa218-929a-4368-a42b-f5ec8f81ccf8\n",
            "[I 2023-11-29 10:50:35,523] Trial 0 finished with value: 0.4588407874107361 and parameters: {'hidden_layer1_size': 38, 'hidden_layer2_size': 38, 'hidden_layer3_size': 11, 'learning_rate': 2.6226151824229484e-05}. Best is trial 0 with value: 0.4588407874107361.\n",
            "[I 2023-11-29 10:51:25,083] Trial 1 finished with value: 0.014299485832452774 and parameters: {'hidden_layer1_size': 47, 'hidden_layer2_size': 48, 'hidden_layer3_size': 9, 'learning_rate': 0.03434194087340384}. Best is trial 1 with value: 0.014299485832452774.\n",
            "[I 2023-11-29 10:52:25,863] Trial 2 finished with value: 0.008214987814426422 and parameters: {'hidden_layer1_size': 46, 'hidden_layer2_size': 49, 'hidden_layer3_size': 34, 'learning_rate': 0.00023418526219720745}. Best is trial 2 with value: 0.008214987814426422.\n",
            "[I 2023-11-29 10:52:57,708] Trial 3 finished with value: 0.0069025177508592606 and parameters: {'hidden_layer1_size': 15, 'hidden_layer2_size': 26, 'hidden_layer3_size': 30, 'learning_rate': 0.002667181953071024}. Best is trial 3 with value: 0.0069025177508592606.\n",
            "[I 2023-11-29 10:53:30,907] Trial 4 finished with value: 0.006860794965177774 and parameters: {'hidden_layer1_size': 12, 'hidden_layer2_size': 8, 'hidden_layer3_size': 25, 'learning_rate': 0.003566134708450814}. Best is trial 4 with value: 0.006860794965177774.\n",
            "[I 2023-11-29 10:54:06,586] Trial 5 finished with value: 0.018694616854190826 and parameters: {'hidden_layer1_size': 12, 'hidden_layer2_size': 10, 'hidden_layer3_size': 37, 'learning_rate': 0.00023986290566604447}. Best is trial 4 with value: 0.006860794965177774.\n",
            "[I 2023-11-29 10:54:36,903] Trial 6 finished with value: 0.015943972393870354 and parameters: {'hidden_layer1_size': 21, 'hidden_layer2_size': 16, 'hidden_layer3_size': 4, 'learning_rate': 0.0006003109030961849}. Best is trial 4 with value: 0.006860794965177774.\n",
            "[I 2023-11-29 10:55:02,994] Trial 7 finished with value: 0.05963505432009697 and parameters: {'hidden_layer1_size': 50, 'hidden_layer2_size': 31, 'hidden_layer3_size': 33, 'learning_rate': 0.08443093322403593}. Best is trial 4 with value: 0.006860794965177774.\n",
            "[I 2023-11-29 10:55:26,759] Trial 8 finished with value: 1.1117985248565674 and parameters: {'hidden_layer1_size': 6, 'hidden_layer2_size': 4, 'hidden_layer3_size': 26, 'learning_rate': 4.553913536050332e-05}. Best is trial 4 with value: 0.006860794965177774.\n",
            "[I 2023-11-29 10:55:50,926] Trial 9 finished with value: 0.008135361596941948 and parameters: {'hidden_layer1_size': 32, 'hidden_layer2_size': 30, 'hidden_layer3_size': 6, 'learning_rate': 8.715383397073464e-05}. Best is trial 4 with value: 0.006860794965177774.\n",
            "[I 2023-11-29 10:56:10,371] Trial 10 finished with value: 0.014603734016418457 and parameters: {'hidden_layer1_size': 25, 'hidden_layer2_size': 17, 'hidden_layer3_size': 49, 'learning_rate': 0.0038191324752067956}. Best is trial 4 with value: 0.006860794965177774.\n",
            "[I 2023-11-29 10:56:29,393] Trial 11 finished with value: 0.007307345513254404 and parameters: {'hidden_layer1_size': 13, 'hidden_layer2_size': 21, 'hidden_layer3_size': 21, 'learning_rate': 0.003412844715717543}. Best is trial 4 with value: 0.006860794965177774.\n",
            "[I 2023-11-29 10:56:47,374] Trial 12 finished with value: 0.009113641455769539 and parameters: {'hidden_layer1_size': 17, 'hidden_layer2_size': 2, 'hidden_layer3_size': 19, 'learning_rate': 0.0036849210976540397}. Best is trial 4 with value: 0.006860794965177774.\n",
            "[I 2023-11-29 10:57:06,451] Trial 13 finished with value: 0.5984675288200378 and parameters: {'hidden_layer1_size': 2, 'hidden_layer2_size': 38, 'hidden_layer3_size': 39, 'learning_rate': 0.009568868350293398}. Best is trial 4 with value: 0.006860794965177774.\n",
            "[I 2023-11-29 10:57:25,872] Trial 14 finished with value: 0.00929972343146801 and parameters: {'hidden_layer1_size': 9, 'hidden_layer2_size': 11, 'hidden_layer3_size': 27, 'learning_rate': 0.0014557559179718326}. Best is trial 4 with value: 0.006860794965177774.\n",
            "[I 2023-11-29 10:57:48,471] Trial 15 finished with value: 0.009614800103008747 and parameters: {'hidden_layer1_size': 20, 'hidden_layer2_size': 24, 'hidden_layer3_size': 44, 'learning_rate': 0.009962334511191247}. Best is trial 4 with value: 0.006860794965177774.\n",
            "[I 2023-11-29 10:58:13,315] Trial 16 finished with value: 0.007635872345417738 and parameters: {'hidden_layer1_size': 26, 'hidden_layer2_size': 10, 'hidden_layer3_size': 17, 'learning_rate': 0.000760405712765673}. Best is trial 4 with value: 0.006860794965177774.\n",
            "[I 2023-11-29 10:58:37,272] Trial 17 finished with value: 0.0074988785199820995 and parameters: {'hidden_layer1_size': 32, 'hidden_layer2_size': 39, 'hidden_layer3_size': 26, 'learning_rate': 0.015083423107464118}. Best is trial 4 with value: 0.006860794965177774.\n",
            "[I 2023-11-29 10:58:59,622] Trial 18 finished with value: 0.006848945282399654 and parameters: {'hidden_layer1_size': 14, 'hidden_layer2_size': 28, 'hidden_layer3_size': 29, 'learning_rate': 0.0017735025984498996}. Best is trial 18 with value: 0.006848945282399654.\n",
            "[I 2023-11-29 10:59:20,593] Trial 19 finished with value: 0.01781492307782173 and parameters: {'hidden_layer1_size': 2, 'hidden_layer2_size': 31, 'hidden_layer3_size': 14, 'learning_rate': 0.0009429109828489393}. Best is trial 18 with value: 0.006848945282399654.\n",
            "[I 2023-11-29 10:59:41,264] Trial 20 finished with value: 1.9147229194641113 and parameters: {'hidden_layer1_size': 8, 'hidden_layer2_size': 21, 'hidden_layer3_size': 20, 'learning_rate': 1.1392639873568741e-05}. Best is trial 18 with value: 0.006848945282399654.\n",
            "[I 2023-11-29 11:00:02,004] Trial 21 finished with value: 0.007297466974705458 and parameters: {'hidden_layer1_size': 15, 'hidden_layer2_size': 26, 'hidden_layer3_size': 28, 'learning_rate': 0.001764667282191432}. Best is trial 18 with value: 0.006848945282399654.\n",
            "[I 2023-11-29 11:00:24,232] Trial 22 finished with value: 0.02564689703285694 and parameters: {'hidden_layer1_size': 19, 'hidden_layer2_size': 42, 'hidden_layer3_size': 32, 'learning_rate': 0.0028222819099102477}. Best is trial 18 with value: 0.006848945282399654.\n",
            "[I 2023-11-29 11:00:46,317] Trial 23 finished with value: 0.007166177965700626 and parameters: {'hidden_layer1_size': 11, 'hidden_layer2_size': 34, 'hidden_layer3_size': 23, 'learning_rate': 0.005145373446960568}. Best is trial 18 with value: 0.006848945282399654.\n",
            "[I 2023-11-29 11:01:07,220] Trial 24 finished with value: 0.007728306110948324 and parameters: {'hidden_layer1_size': 25, 'hidden_layer2_size': 14, 'hidden_layer3_size': 30, 'learning_rate': 0.0017540371225719775}. Best is trial 18 with value: 0.006848945282399654.\n",
            "[I 2023-11-29 11:01:31,928] Trial 25 finished with value: 0.008670325390994549 and parameters: {'hidden_layer1_size': 6, 'hidden_layer2_size': 27, 'hidden_layer3_size': 40, 'learning_rate': 0.00042385594551435626}. Best is trial 18 with value: 0.006848945282399654.\n",
            "[I 2023-11-29 11:01:59,727] Trial 26 finished with value: 0.007415867410600185 and parameters: {'hidden_layer1_size': 16, 'hidden_layer2_size': 21, 'hidden_layer3_size': 23, 'learning_rate': 0.0014971704618927258}. Best is trial 18 with value: 0.006848945282399654.\n",
            "[I 2023-11-29 11:02:22,459] Trial 27 finished with value: 0.007708536460995674 and parameters: {'hidden_layer1_size': 22, 'hidden_layer2_size': 35, 'hidden_layer3_size': 35, 'learning_rate': 0.010470624561245714}. Best is trial 18 with value: 0.006848945282399654.\n",
            "[I 2023-11-29 11:02:46,464] Trial 28 finished with value: 0.017034858465194702 and parameters: {'hidden_layer1_size': 30, 'hidden_layer2_size': 7, 'hidden_layer3_size': 30, 'learning_rate': 0.006245403149240321}. Best is trial 18 with value: 0.006848945282399654.\n",
            "[I 2023-11-29 11:03:14,550] Trial 29 finished with value: 0.015726815909147263 and parameters: {'hidden_layer1_size': 39, 'hidden_layer2_size': 44, 'hidden_layer3_size': 14, 'learning_rate': 0.021166762455913996}. Best is trial 18 with value: 0.006848945282399654.\n",
            "[I 2023-11-29 11:03:45,395] Trial 30 finished with value: 0.007246062625199556 and parameters: {'hidden_layer1_size': 15, 'hidden_layer2_size': 18, 'hidden_layer3_size': 42, 'learning_rate': 0.0025391504534832666}. Best is trial 18 with value: 0.006848945282399654.\n",
            "[I 2023-11-29 11:04:10,560] Trial 31 finished with value: 0.007156240753829479 and parameters: {'hidden_layer1_size': 11, 'hidden_layer2_size': 36, 'hidden_layer3_size': 23, 'learning_rate': 0.005573499599960318}. Best is trial 18 with value: 0.006848945282399654.\n",
            "[I 2023-11-29 11:04:33,170] Trial 32 finished with value: 0.007637152913957834 and parameters: {'hidden_layer1_size': 10, 'hidden_layer2_size': 35, 'hidden_layer3_size': 23, 'learning_rate': 0.006400735041268625}. Best is trial 18 with value: 0.006848945282399654.\n",
            "[I 2023-11-29 11:04:54,482] Trial 33 finished with value: 0.006831951439380646 and parameters: {'hidden_layer1_size': 6, 'hidden_layer2_size': 45, 'hidden_layer3_size': 16, 'learning_rate': 0.0011311412313247896}. Best is trial 33 with value: 0.006831951439380646.\n",
            "[I 2023-11-29 11:05:15,652] Trial 34 finished with value: 0.008129321038722992 and parameters: {'hidden_layer1_size': 5, 'hidden_layer2_size': 44, 'hidden_layer3_size': 9, 'learning_rate': 0.0010608973103673907}. Best is trial 33 with value: 0.006831951439380646.\n",
            "[I 2023-11-29 11:05:38,163] Trial 35 finished with value: 0.008581753820180893 and parameters: {'hidden_layer1_size': 14, 'hidden_layer2_size': 50, 'hidden_layer3_size': 15, 'learning_rate': 0.00044055485174780365}. Best is trial 33 with value: 0.006831951439380646.\n",
            "[I 2023-11-29 11:06:00,709] Trial 36 finished with value: 0.01012144424021244 and parameters: {'hidden_layer1_size': 18, 'hidden_layer2_size': 47, 'hidden_layer3_size': 11, 'learning_rate': 0.002197114326817612}. Best is trial 33 with value: 0.006831951439380646.\n",
            "[I 2023-11-29 11:06:21,692] Trial 37 finished with value: 0.01136775966733694 and parameters: {'hidden_layer1_size': 5, 'hidden_layer2_size': 14, 'hidden_layer3_size': 30, 'learning_rate': 0.0002833984797052497}. Best is trial 33 with value: 0.006831951439380646.\n",
            "[I 2023-11-29 11:06:43,110] Trial 38 finished with value: 0.013505013659596443 and parameters: {'hidden_layer1_size': 7, 'hidden_layer2_size': 29, 'hidden_layer3_size': 33, 'learning_rate': 0.0010046731097232986}. Best is trial 33 with value: 0.006831951439380646.\n",
            "[I 2023-11-29 11:07:04,549] Trial 39 finished with value: 0.016464808955788612 and parameters: {'hidden_layer1_size': 23, 'hidden_layer2_size': 6, 'hidden_layer3_size': 37, 'learning_rate': 0.000523700794838657}. Best is trial 33 with value: 0.006831951439380646.\n",
            "[I 2023-11-29 11:07:27,102] Trial 40 finished with value: 0.011567311361432076 and parameters: {'hidden_layer1_size': 13, 'hidden_layer2_size': 41, 'hidden_layer3_size': 3, 'learning_rate': 0.0007257727662103829}. Best is trial 33 with value: 0.006831951439380646.\n",
            "[I 2023-11-29 11:07:51,579] Trial 41 finished with value: 0.01321971695870161 and parameters: {'hidden_layer1_size': 11, 'hidden_layer2_size': 47, 'hidden_layer3_size': 24, 'learning_rate': 0.005404845755604154}. Best is trial 33 with value: 0.006831951439380646.\n",
            "[I 2023-11-29 11:08:16,717] Trial 42 finished with value: 0.008347611874341965 and parameters: {'hidden_layer1_size': 9, 'hidden_layer2_size': 32, 'hidden_layer3_size': 18, 'learning_rate': 0.0028539425518305673}. Best is trial 33 with value: 0.006831951439380646.\n",
            "[I 2023-11-29 11:08:42,986] Trial 43 finished with value: 0.006784788332879543 and parameters: {'hidden_layer1_size': 4, 'hidden_layer2_size': 36, 'hidden_layer3_size': 21, 'learning_rate': 0.004106430533358525}. Best is trial 43 with value: 0.006784788332879543.\n",
            "[I 2023-11-29 11:09:13,262] Trial 44 finished with value: 0.008763688616454601 and parameters: {'hidden_layer1_size': 3, 'hidden_layer2_size': 24, 'hidden_layer3_size': 28, 'learning_rate': 0.0012185512686472056}. Best is trial 43 with value: 0.006784788332879543.\n",
            "[I 2023-11-29 11:09:42,413] Trial 45 finished with value: 0.009582703933119774 and parameters: {'hidden_layer1_size': 4, 'hidden_layer2_size': 28, 'hidden_layer3_size': 20, 'learning_rate': 0.0032812822270754803}. Best is trial 43 with value: 0.006784788332879543.\n",
            "[I 2023-11-29 11:10:14,736] Trial 46 finished with value: 0.007490797899663448 and parameters: {'hidden_layer1_size': 7, 'hidden_layer2_size': 39, 'hidden_layer3_size': 16, 'learning_rate': 0.0019737519629754318}. Best is trial 43 with value: 0.006784788332879543.\n",
            "[I 2023-11-29 11:10:50,318] Trial 47 finished with value: 0.009689845144748688 and parameters: {'hidden_layer1_size': 41, 'hidden_layer2_size': 45, 'hidden_layer3_size': 12, 'learning_rate': 0.004092254073489606}. Best is trial 43 with value: 0.006784788332879543.\n",
            "[I 2023-11-29 11:11:22,959] Trial 48 finished with value: 0.008272881619632244 and parameters: {'hidden_layer1_size': 12, 'hidden_layer2_size': 41, 'hidden_layer3_size': 25, 'learning_rate': 0.0022540132845055368}. Best is trial 43 with value: 0.006784788332879543.\n",
            "[I 2023-11-29 11:11:53,824] Trial 49 finished with value: 0.01888827048242092 and parameters: {'hidden_layer1_size': 17, 'hidden_layer2_size': 24, 'hidden_layer3_size': 21, 'learning_rate': 0.00013559458773140535}. Best is trial 43 with value: 0.006784788332879543.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of finished trials: 50\n",
            "Best trial:\n",
            "Value:  0.006784788332879543\n",
            "Params: \n",
            "    hidden_layer1_size: 4\n",
            "    hidden_layer2_size: 36\n",
            "    hidden_layer3_size: 21\n",
            "    learning_rate: 0.004106430533358525\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "\n",
        "def objective(trial):\n",
        "    # Define the hyperparameters to be optimized\n",
        "    hidden_layer1_size = trial.suggest_int('hidden_layer1_size', 2, 50)\n",
        "    hidden_layer2_size = trial.suggest_int('hidden_layer2_size', 2, 50)\n",
        "    hidden_layer3_size = trial.suggest_int('hidden_layer3_size', 2, 50)\n",
        "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-1,log=True)\n",
        "\n",
        "    # Modify the model architecture based on the sampled hyperparameters\n",
        "    model = MagneticLossPredictor(input_size=3, output_size=1)\n",
        "    \n",
        "    # Adjust the architecture based on the sampled hyperparameters\n",
        "    model.fc1 = nn.Linear(3, hidden_layer1_size)\n",
        "    model.fc2 = nn.Linear(hidden_layer1_size, hidden_layer2_size)\n",
        "    model.fc3 = nn.Linear(hidden_layer2_size, hidden_layer3_size)\n",
        "    model.fc4 = nn.Linear(hidden_layer3_size, 1)\n",
        "\n",
        "    # Define the loss function and the optimizer\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    num_epochs = 50\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        for inputs, targets in train_loader:\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            # Backward and optimize\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Evaluation phase\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        predictions, actuals = torch.tensor([]), torch.tensor([])\n",
        "        for inputs, targets in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            predictions = torch.cat((predictions, outputs), 0)\n",
        "            actuals = torch.cat((actuals, targets), 0)\n",
        "\n",
        "        # Calculate mean squared error (you can modify this to any metric you want to minimize)\n",
        "        mse_loss = criterion(predictions, actuals)\n",
        "\n",
        "    return mse_loss.item()\n",
        "\n",
        "# Rest of the code remains the same\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "print('Number of finished trials:', len(study.trials))\n",
        "print('Best trial:')\n",
        "trial = study.best_trial\n",
        "\n",
        "print('Value: ', trial.value)\n",
        "print('Params: ')\n",
        "for key, value in trial.params.items():\n",
        "    print(f'    {key}: {value}')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
