{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn import functional as F\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    data_dir = '/content/drive/Shareddrives/EEE405 Group Project/MagnetChallenge/data'\n",
    "else:\n",
    "    data_dir = 'C:/Users/moyin/Desktop/N87'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_material_data(material, data_dir=data_dir, first_row=0, last_row=None):\n",
    "    \"\"\"\n",
    "    Load the material data from the data directory.\n",
    "    :return: dict of pandas dataframes\n",
    "    \"\"\"\n",
    "    material_dir = os.path.join(data_dir, material + \"_cycle\")\n",
    "    if last_row is not None:\n",
    "        nrows = last_row - first_row + 1\n",
    "    else:\n",
    "        nrows = None\n",
    "\n",
    "    data_dict = {\n",
    "        \"Freq\": pd.read_csv(os.path.join(material_dir, \"Frequency[Hz].csv\"), nrows=nrows, header=None, skiprows=first_row),\n",
    "        \"Temp\": pd.read_csv(os.path.join(material_dir, \"Temperature[C].csv\"), nrows=nrows, header=None, skiprows=first_row),\n",
    "        \"B\": pd.read_csv(os.path.join(material_dir, \"B_waveform[T].csv\"), header=None, nrows=nrows, skiprows=first_row),\n",
    "        \"H\": pd.read_csv(os.path.join(material_dir, \"H_waveform[Am-1].csv\"), header=None, nrows=nrows, skiprows=first_row),\n",
    "        \"Loss\": pd.read_csv(os.path.join(material_dir, \"Volumetric_losses[Wm-3].csv\"), header=None, nrows=nrows, names=[\"Loss\"], skiprows=first_row),\n",
    "    }\n",
    "\n",
    "    df = pd.concat(data_dict.values(), axis=1, keys=data_dict.keys())\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sine_dfs = load_material_data(\"N87\", first_row=0, last_row=337)\n",
    "triangle_dfs = load_material_data(\"N87\", first_row=338, last_row=3649)\n",
    "trap_dfs = load_material_data(\"N87\", first_row=3650, last_row=10151)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circular_shift_and_add_noise(waveform_df, num_shifts=5, noise_level=0.01):\n",
    "    augmented_data = []\n",
    "\n",
    "    for i in range(num_shifts):\n",
    "        # Circular shift\n",
    "        shifted_waveform = np.roll(waveform_df.values, shift=np.random.randint(len(waveform_df)), axis=0)\n",
    "\n",
    "        # Add white noise\n",
    "        noisy_waveform = shifted_waveform + noise_level * np.random.randn(*shifted_waveform.shape)\n",
    "\n",
    "        augmented_data.append(noisy_waveform)\n",
    "\n",
    "    augmented_data = np.concatenate(augmented_data, axis=0)\n",
    "\n",
    "    # Create a DataFrame from the augmented data without changing column names\n",
    "    augmented_df = pd.DataFrame(data=augmented_data, columns=waveform_df.columns)\n",
    "\n",
    "    return augmented_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sine_dfs = circular_shift_and_add_noise(sine_dfs, num_shifts=40, noise_level=0.01)\n",
    "trap_dfs = circular_shift_and_add_noise(trap_dfs, num_shifts=2, noise_level=0.01)\n",
    "triangle_dfs = circular_shift_and_add_noise(triangle_dfs, num_shifts=4, noise_level=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([sine_dfs, triangle_dfs, trap_dfs], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_data = combined_df.loc[:, ('B', slice(None))].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 128\n",
    "X_lstm_b = b_data.reshape(b_data.shape[0], time_steps, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_data = combined_df.loc[:, ('Loss', 'Loss')].values.flatten()\n",
    "y = np.log10(loss_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lstm_b_tensor = torch.tensor(X_lstm_b, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).view(-1, 1)  # reshape for the output layer\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_lstm_b_tensor, y_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert the data into PyTorch DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer1_size, hidden_layer2_size, hidden_layer3_size, dropout_rate):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        # LSTM layers\n",
    "        self.lstm1 = nn.LSTM(input_size, hidden_layer1_size, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(hidden_layer1_size, hidden_layer2_size, batch_first=True)\n",
    "\n",
    "        # FNN layers\n",
    "        self.fc1 = nn.Linear(hidden_layer2_size, hidden_layer3_size)\n",
    "        self.fc2 = nn.Linear(hidden_layer3_size, 15)\n",
    "        self.fc3 = nn.Linear(15, 9)\n",
    "        self.fc4 = nn.Linear(9, 1)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # LSTM layers\n",
    "        x, _ = self.lstm1(x)\n",
    "        x, _ = self.lstm2(x[:, -1, :].view(x.size(0), 1, -1))\n",
    "\n",
    "        # FNN layers\n",
    "        x = F.relu(self.fc1(x[:, -1, :]))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def relative_error(y_test, y_pred):\n",
    "    avg_rpe = 100 * torch.mean(torch.abs((y_test - y_pred) / y_test))\n",
    "    max_rpe = 100 * torch.max(torch.abs((y_test - y_pred) / y_test))\n",
    "    return avg_rpe.item(), max_rpe.item()\n",
    "\n",
    "# Define the training and evaluation loops\n",
    "def train_and_evaluate(model, train_loader, test_loader, criterion, optimizer, num_epochs=10):\n",
    "    best_model = None\n",
    "    best_avg_rpe = float('inf')  # Set to positive infinity for initialization\n",
    "    best_max_rpe = float('inf')  # Set to positive infinity for initialization\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        for inputs, targets in train_loader:\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Evaluation phase\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            predictions, actuals = torch.tensor([]), torch.tensor([])\n",
    "            for inputs, targets in test_loader:\n",
    "                outputs = model(inputs)\n",
    "                predictions = torch.cat((predictions, outputs), 0)\n",
    "                actuals = torch.cat((actuals, targets), 0)\n",
    "\n",
    "            # Calculate relative errors\n",
    "            avg_rpe, max_rpe = relative_error(actuals, predictions)\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Avg RPE: {avg_rpe:.2f}%, Max RPE: {max_rpe:.2f}%')\n",
    "\n",
    "            # Check if this epoch has better relative errors\n",
    "            if avg_rpe < best_avg_rpe:\n",
    "                best_model = model.state_dict()  # Save the state_dict of the best model\n",
    "                best_avg_rpe = avg_rpe\n",
    "                best_max_rpe = max_rpe\n",
    "\n",
    "    # Load the best model before returning\n",
    "    model.load_state_dict(best_model)\n",
    "\n",
    "    return model, best_avg_rpe, best_max_rpe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Define the hyperparameters to be optimized\n",
    "    hidden_layer1_size = trial.suggest_int('hidden_layer1_size', 2, 50)\n",
    "    hidden_layer2_size = trial.suggest_int('hidden_layer2_size', 2, 50)\n",
    "    hidden_layer3_size = trial.suggest_int('hidden_layer3_size', 2, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.9)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-1, log=True)\n",
    "\n",
    "    \n",
    "    model = CombinedModel(input_size=X_train.shape[2], hidden_layer1_size=hidden_layer1_size,\n",
    "                          hidden_layer2_size=hidden_layer2_size, hidden_layer3_size=hidden_layer3_size,\n",
    "                          dropout_rate=dropout_rate)\n",
    "\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Train and evaluate the model\n",
    "    train_and_evaluate(model, train_loader, test_loader, criterion, optimizer)\n",
    "\n",
    "    # Calculate mean squared error as the objective to minimize\n",
    "    with torch.no_grad():\n",
    "        predictions, actuals = torch.tensor([]), torch.tensor([])\n",
    "        for inputs, targets in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            predictions = torch.cat((predictions, outputs), 0)\n",
    "            actuals = torch.cat((actuals, targets), 0)\n",
    "        mse_loss = criterion(predictions, actuals)\n",
    "\n",
    "    return mse_loss.item()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-29 13:09:27,593] A new study created in memory with name: no-name-dcbc0756-7183-4125-b1ce-01dd532e4f90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.6402, Avg RPE: 14.82%, Max RPE: 56.03%\n",
      "Epoch [2/10], Loss: 0.5164, Avg RPE: 14.41%, Max RPE: 53.43%\n",
      "Epoch [3/10], Loss: 0.1523, Avg RPE: 7.29%, Max RPE: 32.36%\n",
      "Epoch [4/10], Loss: 0.1194, Avg RPE: 6.77%, Max RPE: 28.47%\n",
      "Epoch [5/10], Loss: 0.1541, Avg RPE: 6.80%, Max RPE: 27.44%\n",
      "Epoch [6/10], Loss: 0.1195, Avg RPE: 6.72%, Max RPE: 25.02%\n",
      "Epoch [7/10], Loss: 0.1193, Avg RPE: 6.61%, Max RPE: 29.99%\n",
      "Epoch [8/10], Loss: 0.1312, Avg RPE: 6.83%, Max RPE: 27.25%\n",
      "Epoch [9/10], Loss: 0.1291, Avg RPE: 6.64%, Max RPE: 29.72%\n",
      "Epoch [10/10], Loss: 0.1292, Avg RPE: 6.73%, Max RPE: 28.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-29 13:12:36,920] Trial 0 finished with value: 0.12711727619171143 and parameters: {'hidden_layer1_size': 34, 'hidden_layer2_size': 24, 'hidden_layer3_size': 40, 'dropout_rate': 0.2224775459473375, 'learning_rate': 0.002408028917968372}. Best is trial 0 with value: 0.12711727619171143.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.5782, Avg RPE: 14.65%, Max RPE: 54.99%\n",
      "Epoch [2/10], Loss: 0.2905, Avg RPE: 10.57%, Max RPE: 40.79%\n",
      "Epoch [3/10], Loss: 0.2524, Avg RPE: 10.17%, Max RPE: 42.35%\n",
      "Epoch [4/10], Loss: 0.2558, Avg RPE: 8.63%, Max RPE: 36.75%\n",
      "Epoch [5/10], Loss: 0.2860, Avg RPE: 9.59%, Max RPE: 37.42%\n",
      "Epoch [6/10], Loss: 0.3400, Avg RPE: 9.90%, Max RPE: 41.36%\n",
      "Epoch [7/10], Loss: 0.3329, Avg RPE: 9.89%, Max RPE: 40.32%\n",
      "Epoch [8/10], Loss: 0.2749, Avg RPE: 9.71%, Max RPE: 37.95%\n",
      "Epoch [9/10], Loss: 0.2623, Avg RPE: 9.61%, Max RPE: 37.77%\n",
      "Epoch [10/10], Loss: 0.2413, Avg RPE: 9.18%, Max RPE: 28.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-29 13:16:49,395] Trial 1 finished with value: 0.2996825873851776 and parameters: {'hidden_layer1_size': 42, 'hidden_layer2_size': 37, 'hidden_layer3_size': 33, 'dropout_rate': 0.1113874670770995, 'learning_rate': 0.018317757577226458}. Best is trial 0 with value: 0.12711727619171143.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 8.1122, Avg RPE: 57.83%, Max RPE: 70.34%\n",
      "Epoch [2/10], Loss: 0.5135, Avg RPE: 14.73%, Max RPE: 55.12%\n",
      "Epoch [3/10], Loss: 0.5535, Avg RPE: 14.71%, Max RPE: 54.93%\n",
      "Epoch [4/10], Loss: 0.5802, Avg RPE: 14.72%, Max RPE: 55.10%\n",
      "Epoch [5/10], Loss: 0.6658, Avg RPE: 14.75%, Max RPE: 55.49%\n",
      "Epoch [6/10], Loss: 0.5920, Avg RPE: 14.74%, Max RPE: 55.46%\n",
      "Epoch [7/10], Loss: 0.5804, Avg RPE: 14.67%, Max RPE: 55.01%\n",
      "Epoch [8/10], Loss: 0.1289, Avg RPE: 8.91%, Max RPE: 35.18%\n",
      "Epoch [9/10], Loss: 0.1379, Avg RPE: 7.05%, Max RPE: 28.07%\n",
      "Epoch [10/10], Loss: 0.1152, Avg RPE: 6.75%, Max RPE: 26.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-29 13:19:18,109] Trial 2 finished with value: 0.1331571340560913 and parameters: {'hidden_layer1_size': 38, 'hidden_layer2_size': 22, 'hidden_layer3_size': 47, 'dropout_rate': 0.5140402475924575, 'learning_rate': 0.00021037534319940385}. Best is trial 0 with value: 0.12711727619171143.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 21.1233, Avg RPE: 96.15%, Max RPE: 97.16%\n",
      "Epoch [2/10], Loss: 13.2573, Avg RPE: 74.90%, Max RPE: 82.29%\n",
      "Epoch [3/10], Loss: 4.5676, Avg RPE: 43.57%, Max RPE: 60.32%\n",
      "Epoch [4/10], Loss: 1.1028, Avg RPE: 16.52%, Max RPE: 37.67%\n",
      "Epoch [5/10], Loss: 0.5115, Avg RPE: 14.58%, Max RPE: 53.00%\n",
      "Epoch [6/10], Loss: 0.4751, Avg RPE: 14.70%, Max RPE: 54.81%\n",
      "Epoch [7/10], Loss: 0.5648, Avg RPE: 14.75%, Max RPE: 55.39%\n",
      "Epoch [8/10], Loss: 0.5016, Avg RPE: 14.73%, Max RPE: 55.12%\n",
      "Epoch [9/10], Loss: 0.7553, Avg RPE: 14.73%, Max RPE: 55.11%\n",
      "Epoch [10/10], Loss: 0.5970, Avg RPE: 14.72%, Max RPE: 55.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-29 13:21:26,389] Trial 3 finished with value: 0.5984629392623901 and parameters: {'hidden_layer1_size': 40, 'hidden_layer2_size': 6, 'hidden_layer3_size': 31, 'dropout_rate': 0.21583708703276822, 'learning_rate': 7.365705870260554e-05}. Best is trial 0 with value: 0.12711727619171143.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 18.2351, Avg RPE: 90.33%, Max RPE: 93.19%\n",
      "Epoch [2/10], Loss: 16.5584, Avg RPE: 85.22%, Max RPE: 89.60%\n",
      "Epoch [3/10], Loss: 11.6604, Avg RPE: 68.55%, Max RPE: 77.87%\n",
      "Epoch [4/10], Loss: 3.5712, Avg RPE: 34.89%, Max RPE: 54.24%\n",
      "Epoch [5/10], Loss: 0.7610, Avg RPE: 14.80%, Max RPE: 43.39%\n",
      "Epoch [6/10], Loss: 0.5708, Avg RPE: 14.66%, Max RPE: 54.31%\n",
      "Epoch [7/10], Loss: 0.4882, Avg RPE: 14.72%, Max RPE: 54.98%\n",
      "Epoch [8/10], Loss: 0.7581, Avg RPE: 14.72%, Max RPE: 55.02%\n",
      "Epoch [9/10], Loss: 0.6242, Avg RPE: 14.75%, Max RPE: 55.33%\n",
      "Epoch [10/10], Loss: 0.6075, Avg RPE: 14.73%, Max RPE: 55.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-29 13:23:25,765] Trial 4 finished with value: 0.598741352558136 and parameters: {'hidden_layer1_size': 31, 'hidden_layer2_size': 14, 'hidden_layer3_size': 18, 'dropout_rate': 0.053644688118290165, 'learning_rate': 7.140837264288555e-05}. Best is trial 0 with value: 0.12711727619171143.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.6713, Avg RPE: 14.53%, Max RPE: 51.76%\n",
      "Epoch [2/10], Loss: 0.5378, Avg RPE: 14.72%, Max RPE: 54.92%\n",
      "Epoch [3/10], Loss: 0.6150, Avg RPE: 14.53%, Max RPE: 51.74%\n",
      "Epoch [4/10], Loss: 0.4155, Avg RPE: 14.54%, Max RPE: 52.07%\n",
      "Epoch [5/10], Loss: 0.5789, Avg RPE: 14.91%, Max RPE: 56.81%\n",
      "Epoch [6/10], Loss: 0.7201, Avg RPE: 14.67%, Max RPE: 54.37%\n",
      "Epoch [7/10], Loss: 0.2877, Avg RPE: 9.75%, Max RPE: 39.96%\n",
      "Epoch [8/10], Loss: 0.2171, Avg RPE: 9.67%, Max RPE: 37.47%\n",
      "Epoch [9/10], Loss: 0.2168, Avg RPE: 9.70%, Max RPE: 38.79%\n",
      "Epoch [10/10], Loss: 0.2204, Avg RPE: 9.85%, Max RPE: 41.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-29 13:26:15,710] Trial 5 finished with value: 0.2780955135822296 and parameters: {'hidden_layer1_size': 37, 'hidden_layer2_size': 48, 'hidden_layer3_size': 18, 'dropout_rate': 0.15189465512671987, 'learning_rate': 0.0062064374327208734}. Best is trial 0 with value: 0.12711727619171143.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.6065, Avg RPE: 14.08%, Max RPE: 53.55%\n",
      "Epoch [2/10], Loss: 0.1590, Avg RPE: 7.50%, Max RPE: 29.19%\n",
      "Epoch [3/10], Loss: 0.1522, Avg RPE: 7.11%, Max RPE: 27.54%\n",
      "Epoch [4/10], Loss: 0.1562, Avg RPE: 7.03%, Max RPE: 29.06%\n",
      "Epoch [5/10], Loss: 0.1287, Avg RPE: 6.70%, Max RPE: 29.49%\n",
      "Epoch [6/10], Loss: 0.1254, Avg RPE: 6.76%, Max RPE: 27.82%\n",
      "Epoch [7/10], Loss: 0.1713, Avg RPE: 6.86%, Max RPE: 33.18%\n",
      "Epoch [8/10], Loss: 0.1178, Avg RPE: 6.60%, Max RPE: 30.00%\n",
      "Epoch [9/10], Loss: 0.1550, Avg RPE: 6.77%, Max RPE: 33.97%\n",
      "Epoch [10/10], Loss: 0.1198, Avg RPE: 6.67%, Max RPE: 30.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-29 13:27:53,873] Trial 6 finished with value: 0.12709346413612366 and parameters: {'hidden_layer1_size': 12, 'hidden_layer2_size': 46, 'hidden_layer3_size': 32, 'dropout_rate': 0.841073820164184, 'learning_rate': 0.0016755379087784372}. Best is trial 6 with value: 0.12709346413612366.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.5720, Avg RPE: 15.03%, Max RPE: 57.79%\n",
      "Epoch [2/10], Loss: 0.6977, Avg RPE: 14.94%, Max RPE: 57.07%\n",
      "Epoch [3/10], Loss: 0.6529, Avg RPE: 15.37%, Max RPE: 60.06%\n",
      "Epoch [4/10], Loss: 0.7497, Avg RPE: 14.50%, Max RPE: 50.51%\n",
      "Epoch [5/10], Loss: 0.5994, Avg RPE: 14.64%, Max RPE: 53.81%\n",
      "Epoch [6/10], Loss: 0.5851, Avg RPE: 14.89%, Max RPE: 56.68%\n",
      "Epoch [7/10], Loss: 0.6603, Avg RPE: 14.83%, Max RPE: 56.09%\n",
      "Epoch [8/10], Loss: 0.5381, Avg RPE: 14.68%, Max RPE: 54.40%\n",
      "Epoch [9/10], Loss: 0.4561, Avg RPE: 15.08%, Max RPE: 58.17%\n",
      "Epoch [10/10], Loss: 0.6349, Avg RPE: 15.39%, Max RPE: 60.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-29 13:31:57,025] Trial 7 finished with value: 0.6201292872428894 and parameters: {'hidden_layer1_size': 46, 'hidden_layer2_size': 17, 'hidden_layer3_size': 47, 'dropout_rate': 0.004750923937718976, 'learning_rate': 0.014690855388245196}. Best is trial 6 with value: 0.12709346413612366.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.5258, Avg RPE: 14.77%, Max RPE: 55.46%\n",
      "Epoch [2/10], Loss: 0.5975, Avg RPE: 13.36%, Max RPE: 51.41%\n",
      "Epoch [3/10], Loss: 0.2522, Avg RPE: 9.70%, Max RPE: 38.09%\n",
      "Epoch [4/10], Loss: 0.3336, Avg RPE: 10.07%, Max RPE: 39.82%\n",
      "Epoch [5/10], Loss: 0.2673, Avg RPE: 10.18%, Max RPE: 44.20%\n",
      "Epoch [6/10], Loss: 0.2366, Avg RPE: 9.96%, Max RPE: 40.02%\n",
      "Epoch [7/10], Loss: 0.2228, Avg RPE: 9.95%, Max RPE: 42.74%\n",
      "Epoch [8/10], Loss: 0.2481, Avg RPE: 10.12%, Max RPE: 33.95%\n",
      "Epoch [9/10], Loss: 0.3162, Avg RPE: 10.06%, Max RPE: 40.15%\n",
      "Epoch [10/10], Loss: 0.2403, Avg RPE: 9.84%, Max RPE: 37.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-29 13:36:30,530] Trial 8 finished with value: 0.29059067368507385 and parameters: {'hidden_layer1_size': 42, 'hidden_layer2_size': 30, 'hidden_layer3_size': 40, 'dropout_rate': 0.12362507402220671, 'learning_rate': 0.039070788804978274}. Best is trial 6 with value: 0.12709346413612366.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 20.9816, Avg RPE: 95.89%, Max RPE: 97.12%\n",
      "Epoch [2/10], Loss: 15.7237, Avg RPE: 79.62%, Max RPE: 85.69%\n",
      "Epoch [3/10], Loss: 5.1929, Avg RPE: 45.32%, Max RPE: 61.61%\n",
      "Epoch [4/10], Loss: 1.0542, Avg RPE: 16.38%, Max RPE: 37.46%\n",
      "Epoch [5/10], Loss: 0.5695, Avg RPE: 14.58%, Max RPE: 52.94%\n",
      "Epoch [6/10], Loss: 0.5300, Avg RPE: 14.74%, Max RPE: 55.11%\n",
      "Epoch [7/10], Loss: 0.6706, Avg RPE: 14.75%, Max RPE: 55.27%\n",
      "Epoch [8/10], Loss: 0.6967, Avg RPE: 14.73%, Max RPE: 54.99%\n",
      "Epoch [9/10], Loss: 0.7010, Avg RPE: 14.76%, Max RPE: 55.40%\n",
      "Epoch [10/10], Loss: 0.5286, Avg RPE: 14.73%, Max RPE: 55.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-29 13:44:30,978] Trial 9 finished with value: 0.6000092625617981 and parameters: {'hidden_layer1_size': 50, 'hidden_layer2_size': 49, 'hidden_layer3_size': 2, 'dropout_rate': 0.41422936301466373, 'learning_rate': 0.0004203685286494101}. Best is trial 6 with value: 0.12709346413612366.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 10\n",
      "Best trial:\n",
      "Value:  0.12709346413612366\n",
      "Params: \n",
      "    hidden_layer1_size: 12\n",
      "    hidden_layer2_size: 46\n",
      "    hidden_layer3_size: 32\n",
      "    dropout_rate: 0.841073820164184\n",
      "    learning_rate: 0.0016755379087784372\n"
     ]
    }
   ],
   "source": [
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "\n",
    "print('Value: ', trial.value)\n",
    "print('Params: ')\n",
    "for key, value in trial.params.items():\n",
    "    print(f'    {key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.5703, Avg RPE: 13.86%, Max RPE: 52.61%\n",
      "Epoch [2/50], Loss: 0.1554, Avg RPE: 7.81%, Max RPE: 31.27%\n",
      "Epoch [3/50], Loss: 0.1300, Avg RPE: 7.13%, Max RPE: 26.96%\n",
      "Epoch [4/50], Loss: 0.1448, Avg RPE: 6.99%, Max RPE: 26.33%\n",
      "Epoch [5/50], Loss: 0.1381, Avg RPE: 6.83%, Max RPE: 26.15%\n",
      "Epoch [6/50], Loss: 0.1381, Avg RPE: 6.67%, Max RPE: 28.08%\n",
      "Epoch [7/50], Loss: 0.1121, Avg RPE: 6.62%, Max RPE: 31.21%\n",
      "Epoch [8/50], Loss: 0.1409, Avg RPE: 6.65%, Max RPE: 29.83%\n",
      "Epoch [9/50], Loss: 0.1563, Avg RPE: 6.65%, Max RPE: 25.57%\n",
      "Epoch [10/50], Loss: 0.1324, Avg RPE: 6.72%, Max RPE: 29.22%\n",
      "Epoch [11/50], Loss: 0.1445, Avg RPE: 6.83%, Max RPE: 30.95%\n",
      "Epoch [12/50], Loss: 0.1095, Avg RPE: 6.56%, Max RPE: 27.91%\n",
      "Epoch [13/50], Loss: 0.1328, Avg RPE: 6.58%, Max RPE: 29.98%\n",
      "Epoch [14/50], Loss: 0.0959, Avg RPE: 6.55%, Max RPE: 29.77%\n",
      "Epoch [15/50], Loss: 0.1102, Avg RPE: 6.61%, Max RPE: 29.27%\n",
      "Epoch [16/50], Loss: 0.1219, Avg RPE: 6.65%, Max RPE: 30.52%\n",
      "Epoch [17/50], Loss: 0.1404, Avg RPE: 6.88%, Max RPE: 30.89%\n",
      "Epoch [18/50], Loss: 0.1220, Avg RPE: 6.58%, Max RPE: 28.41%\n",
      "Epoch [19/50], Loss: 0.1367, Avg RPE: 6.73%, Max RPE: 30.61%\n",
      "Epoch [20/50], Loss: 0.1409, Avg RPE: 7.39%, Max RPE: 33.10%\n",
      "Epoch [21/50], Loss: 0.1292, Avg RPE: 6.78%, Max RPE: 30.40%\n",
      "Epoch [22/50], Loss: 0.1153, Avg RPE: 6.62%, Max RPE: 31.03%\n",
      "Epoch [23/50], Loss: 0.1265, Avg RPE: 6.72%, Max RPE: 30.38%\n",
      "Epoch [24/50], Loss: 0.1272, Avg RPE: 6.67%, Max RPE: 28.94%\n",
      "Epoch [25/50], Loss: 0.1334, Avg RPE: 6.54%, Max RPE: 27.27%\n",
      "Epoch [26/50], Loss: 0.1086, Avg RPE: 6.56%, Max RPE: 31.60%\n",
      "Epoch [27/50], Loss: 0.1357, Avg RPE: 6.54%, Max RPE: 28.85%\n",
      "Epoch [28/50], Loss: 0.1234, Avg RPE: 6.55%, Max RPE: 30.80%\n",
      "Epoch [29/50], Loss: 0.1353, Avg RPE: 6.52%, Max RPE: 29.37%\n",
      "Epoch [30/50], Loss: 0.1087, Avg RPE: 6.53%, Max RPE: 30.66%\n",
      "Epoch [31/50], Loss: 0.1133, Avg RPE: 6.79%, Max RPE: 31.56%\n",
      "Epoch [32/50], Loss: 0.1318, Avg RPE: 6.63%, Max RPE: 31.00%\n",
      "Epoch [33/50], Loss: 0.1452, Avg RPE: 6.70%, Max RPE: 31.97%\n",
      "Epoch [34/50], Loss: 0.1141, Avg RPE: 6.56%, Max RPE: 29.20%\n",
      "Epoch [35/50], Loss: 0.1451, Avg RPE: 6.66%, Max RPE: 29.44%\n",
      "Epoch [36/50], Loss: 0.1149, Avg RPE: 6.54%, Max RPE: 27.52%\n",
      "Epoch [37/50], Loss: 0.1280, Avg RPE: 6.58%, Max RPE: 32.02%\n",
      "Epoch [38/50], Loss: 0.1077, Avg RPE: 6.52%, Max RPE: 28.65%\n",
      "Epoch [39/50], Loss: 0.1161, Avg RPE: 6.76%, Max RPE: 33.74%\n",
      "Epoch [40/50], Loss: 0.1285, Avg RPE: 6.47%, Max RPE: 29.68%\n",
      "Epoch [41/50], Loss: 0.1296, Avg RPE: 6.47%, Max RPE: 29.38%\n",
      "Epoch [42/50], Loss: 0.1395, Avg RPE: 6.49%, Max RPE: 29.15%\n",
      "Epoch [43/50], Loss: 0.1204, Avg RPE: 6.59%, Max RPE: 30.74%\n",
      "Epoch [44/50], Loss: 0.0916, Avg RPE: 6.51%, Max RPE: 26.48%\n",
      "Epoch [45/50], Loss: 0.1490, Avg RPE: 6.49%, Max RPE: 30.50%\n",
      "Epoch [46/50], Loss: 0.0818, Avg RPE: 6.47%, Max RPE: 30.64%\n",
      "Epoch [47/50], Loss: 0.1121, Avg RPE: 6.47%, Max RPE: 27.10%\n",
      "Epoch [48/50], Loss: 0.1318, Avg RPE: 6.56%, Max RPE: 27.10%\n",
      "Epoch [49/50], Loss: 0.1158, Avg RPE: 6.52%, Max RPE: 28.54%\n",
      "Epoch [50/50], Loss: 0.1117, Avg RPE: 6.43%, Max RPE: 28.80%\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have already run the optimization and have the best trial\n",
    "best_trial = study.best_trial\n",
    "\n",
    "# Extract the best parameters\n",
    "best_params = best_trial.params\n",
    "hidden_layer1_size = best_params['hidden_layer1_size']\n",
    "hidden_layer2_size = best_params['hidden_layer2_size']\n",
    "hidden_layer3_size = best_params['hidden_layer3_size']\n",
    "dropout_rate = best_params['dropout_rate']\n",
    "learning_rate = best_params['learning_rate']\n",
    "\n",
    "# Create an instance of CombinedModel with the best parameters\n",
    "best_model = CombinedModel(input_size=X_train.shape[2], hidden_layer1_size=hidden_layer1_size,\n",
    "                            hidden_layer2_size=hidden_layer2_size, hidden_layer3_size=hidden_layer3_size,\n",
    "                            dropout_rate=dropout_rate)\n",
    "\n",
    "# Define the loss function and the optimizer with the best learning rate\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model using the best parameters\n",
    "trained_model, best_avg_rpe, best_max_rpe = train_and_evaluate(best_model, train_loader, test_loader, criterion, optimizer, num_epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trained_model, 'C:/Users/moyin/Desktop/ML BASICS IN DEPLOYMENT TO FPGAS/EXTRA CREDIT/lstm.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CombinedModel(\n",
       "  (lstm1): LSTM(8, 12, batch_first=True)\n",
       "  (lstm2): LSTM(12, 46, batch_first=True)\n",
       "  (fc1): Linear(in_features=46, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=15, bias=True)\n",
       "  (fc3): Linear(in_features=15, out_features=9, bias=True)\n",
       "  (fc4): Linear(in_features=9, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.841073820164184, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = CombinedModel(input_size=X_train.shape[2], hidden_layer1_size=hidden_layer1_size,\n",
    "                            hidden_layer2_size=hidden_layer2_size, hidden_layer3_size=hidden_layer3_size,\n",
    "                            dropout_rate=dropout_rate)\n",
    "\n",
    "torch.save(loaded_model.state_dict(), 'C:/Users/moyin/Desktop/ML BASICS IN DEPLOYMENT TO FPGAS/EXTRA CREDIT/lstm.pth')\n",
    "loaded_model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
